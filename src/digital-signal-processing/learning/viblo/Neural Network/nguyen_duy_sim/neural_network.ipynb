{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mạng nơ-ron nhân tạo (NN) là một mô hình lập trình rất đẹp lấy cảm hứng từ nơ-ron thần kinh. Kết hợp với các kĩ thuật học sâu (DL), NN đang trở thành một công cụ rất mạnh mẽ mang lại hiệu quả tốt nhất cho nhiều bài toán khó như nhận dạng ảnh, giọng nói hay xử lý ngôn ngữ tự nhiên.",
   "id": "a61e9339edffa835"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Perceptrons",
   "id": "451c2c4c2ee85401"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 Perceptron cơ bản",
   "id": "6558dd90fa4d39b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Một mạng nơ-ron được cấu thành bởi các nơ-ron đơn lẻ được gọi là perceptron. Nên trước tiên ta tìm hiểu xem perceptron là gì đã rồi tiến tới mô hình mạng nơ-ron sau. Nơ-ron nhân tạo được lấy cảm hứng từ nơ-ron sinh học như hình:",
   "id": "a26c239b7152c7e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](image1.png)",
   "id": "fa5e3eb0cb8f5b10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Một nơ-ron có thể nhận nhiều đầu vào và cho ra một kết quả duy nhất. Mô hình của perceptron cũng tương tự như vậy:",
   "id": "e79b2c1c992964c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](image2.png)",
   "id": "80ba67ee3a4ae0ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Một perceptron sẽ nhận một hoặc nhiều đầu $x$ vào dạng nhị phân và cho ra một kết quả dạng nhị phân duy nhất. Các đầu vào được điều phối tầm ảnh hưởng bởi các tham số trọng lượng tương ứng $w$ của nó, còn kết quả đầu ra được quyết định dựa vào một ngưỡng quyết định  $b$ nào đó:",
   "id": "2eec3068654cdd4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "o=\n",
    "\\begin{cases}\n",
    "0 & \\text{if} \\space \\sum_{i}{w_{i}x_{i}} \\leq threshold \\\\ \\\\\n",
    "1 & \\text{if} \\space \\sum_{i}{w_{i}x_{i}} > threshold\n",
    "\\end{cases}\n",
    "$$"
   ],
   "id": "e9c61796bc0823c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Đặt $b$=-threshold, ta có thể viết lại thành:",
   "id": "25b2bc3b5bb25043"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "o=\n",
    "\\begin{cases}\n",
    "0 & \\text{if} \\space \\sum_{i}{w_{i}x_{i}} + b \\leq 0 \\\\ \\\\\n",
    "1 & \\text{if} \\space \\sum_{i}{w_{i}x_{i}} + b > 0\n",
    "\\end{cases}\n",
    "$$"
   ],
   "id": "2edbf8c8252b0f49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Để dễ hình dung, ta lấy ví dụ việc đi nhậu hay không phụ thuộc vào 4 yếu tố sau:\n",
    "- 1. Trời có nắng hay không?\n",
    "- 2. Có hẹn trước hay không?\n",
    "- 3. Vợ có vui hay không?\n",
    "- 4. Bạn nhậu có ít khi gặp được hay không? Thì ta coi 4 yếu tố đầu vào là $x_{1}, x_{2}, x_{3}, x_{4}$ và nếu $o$=0 thì ta không đi nhậu, còn $o$=1 thì ta đi nhậu. Giả sử mức độ quan trọng của 4 yếu tố trên lần lượt là $w_{1}=0.05, w_{2}=0.5, w_{3}=0.2, w_{4}=0.25$ và chọn ngưỡng $b=-0.5$ thì ta có thể thấy rằng việc trời nắng có ảnh hưởng chỉ 5% tới quyết định đi nhậu và việc có hẹn từ trước ảnh hưởng tới 50% quyết định đi nhậu của ta. Nếu gắn $x_{0}=1$ và $w_{0}=b$, ta có thể viết gọn:\n",
    "$$\n",
    "o=\n",
    "\\begin{cases}\n",
    "0 & \\text{if} \\space w^{T}x \\leq 0 \\\\ \\\\\n",
    "1 & \\text{if} \\space w^{T}x > 0\n",
    "\\end{cases}\n",
    "$$"
   ],
   "id": "2121cd67e1103a6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 Sigmoid Neurons",
   "id": "46ac7b86efbd8e9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Với đầu vào và đầu ra dạng nhị phân, ta rất khó có thể điều chỉnh một lượng nhỏ đầu vào để đầu ra thay đổi chút ít, nên để linh động, ta có thể mở rộng chúng ta cả khoảng [0, 1]. Lúc này đầu ra được quyết định bởi một hàm $sigmoid$ σ$(w^{T}x)$. Hàm sigmoid có công thức:",
   "id": "20dbf327426a2eed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "σ(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ],
   "id": "528b3e86ece00003"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Đồ thị của hàm này cũng cân xứng rât đẹp thể hiện được mức độ công bằng của các tham số:",
   "id": "a88d6267ef998f7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](image3.png)",
   "id": "4af81dcc2c993033"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Đặt $z=w^{T}x$ thì công thức của perceptron lúc này sẽ có dạng:",
   "id": "ad6cdb9eacee3b27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "o = σ(z) = \\frac{1}{1+exp(-w^{T}x)}\n",
    "$$"
   ],
   "id": "f17232cbe0bbaed1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tới đây thì ta có thể thấy rằng mỗi sigmoid neuron cũng tương tự như một bố phân loại tuyến tính (logistic regression) bởi xác suất $P(y_{i}|x_{i},w)=\\sigma(w^{T}x)$. Thực ra thì ngoài hàm sigmoid ra, ta còn có thể một số hàm khác như tanh ReLU để thay thế hàm sigmoid bởi dạng đồ thị của nó cũng tương tự như sigmoid. Một cách tổng quát hàm perception được biểu diễn qua một hàm kích hoạt (activation function) $f(z)$ như sau: $o=f(z)=f(w^{T}x)$ bằng cách biểu diễn như vậy, ta có thể coi neuron sinh học được thể hiện như sau:",
   "id": "af71056c8da0b789"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](image4.png)",
   "id": "fe7338a0e108478e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Một điểm cần lưu ý là các hàm kích hoạt buộc phải là $\\textbf{hàm phi tuyến.}$",
   "id": "acb0cf33dbb2e8f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vì nếu nó là tuyến tính thì khi kết hợp với phép toán tuyến tính $w^{T}x$ thì kết quả thu được cũng sẽ là một thao tác tuyến tính dẫn chuyện nó trở nên vô nghĩa.",
   "id": "8ae374ea1cb482ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Kiến trúc mạng NN",
   "id": "4562da7fa99730ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mạng NN là sự kết hợp của các tầng perceptron hay còn được gọi là perceptron đa tầng (multilayer perceptron) như hình vẽ bên dưới:",
   "id": "b81e83068b1cbdf1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](image5.png)",
   "id": "a8c178b5f7c8c2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Một mạng NN sẽ có 3 kiểu tầng:\n",
    "- Tầng vào (input layer): là tầng bên trái cùng của mạng thể hiện cho các đầu vào cuả mạng.\n",
    "- Tầng ra (output layer): là tầng bên phải cùng của mạng thể hiện cho các đầu ra của mạng.\n",
    "- Tầng ẩn (hidden layer): là tầng nằm giữa tàng vào ra tầng ra thể hiện cho việc suy luận logic của mạng"
   ],
   "id": "1377df6b78c2c917"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Lưu ý rằng: một NN chỉ có 1 tầng vào và 1 tầng ra nhưng có thể có nhiều tầng ẩn.",
   "id": "4e286f34633f1d77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](image6.png)",
   "id": "9f8dff16440bc274"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Trong mạng NN, mỗi nút mạng là một sigmoid nơ-ron nhưng hàm kích hoạt của chúng có thể khác nhau. Tuy nhiên trong thực tế người ta thường để chúng cùng dạng với nhau để tính toán cho thuận lợi.",
   "id": "9e9a8068f6056ae4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ở mỗi tầng, số lượng các nút mạng (nơ-ron) có thể khác nhau tuỳ thuộc vào bài toán và cách giải quyết. Nhưng thường khi làm việc, người ta để các tầng ẩn có số lượng nơ-ron bằng nhau. Ngoài ra, các nơ-ron ở các tầng thường được liên kết đôi với nhau tạo thành mạng kết nối đầy đủ (full-connected network). Khi đó ta có thể tính được kích cỡ của mạng dựa vào số tầng và số nơ-ron. Ví dụ ở hình trên ta có:\n",
    "- 4 tầng mạng, trong đó có 22 tầng ẩn.\n",
    "- 3+4$*$2+1 = 123+4$*$2+1 = 12 nút mạng\n",
    "- (34+44+4$*$1) + (4+4+1) = 41(3$*$4+4$*$4+4$*$1) + (4+4+1) = 41 tham số"
   ],
   "id": "8200f8baa295213c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "38b57dd23e8cae9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
