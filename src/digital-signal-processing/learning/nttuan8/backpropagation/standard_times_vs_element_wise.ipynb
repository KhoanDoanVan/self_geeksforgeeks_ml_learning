{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üî¨ Ph√¢n t√≠ch c√°c Ph√©p nh√¢n Ma tr·∫≠n trong Neural Networks (ML/DL)\n",
    "\n",
    "T√†i li·ªáu n√†y so s√°nh hai ph√©p to√°n ma tr·∫≠n c·ªët l√µi: **T√≠ch Ma tr·∫≠n Ti√™u chu·∫©n** (Matrix Multiplication) v√† **T√≠ch Hadamard** (Element-wise Multiplication), c√πng v·ªõi ·ª©ng d·ª•ng c·ªßa ch√∫ng trong qu√° tr√¨nh lan truy·ªÅn xu√¥i v√† lan truy·ªÅn ng∆∞·ª£c c·ªßa M·∫°ng N∆°-ron (Neural Networks).\n",
    "\n",
    "---\n",
    "\n",
    "## 1. üÜö So S√°nh T·ªïng quan\n",
    "\n",
    "| ƒê·∫∑c ƒëi·ªÉm | T√≠ch Ma tr·∫≠n Ti√™u chu·∫©n ($\\cdot$ ho·∫∑c $*$) | T√≠ch Hadamard ($\\odot$ ho·∫∑c $\\otimes$) |\n",
    "| :--- | :--- | :--- |\n",
    "| **K√Ω hi·ªáu** | $*$, $\\cdot$ | $\\odot$, $\\otimes$ |\n",
    "| **·ª®ng d·ª•ng ch√≠nh trong NN** | **Lan truy·ªÅn xu√¥i (Forward Prop.)** v√† **Lan truy·ªÅn ng∆∞·ª£c (Backprop.)** qua Ma tr·∫≠n Tr·ªçng s·ªë ($W$). | **√Åp d·ª•ng ƒê·∫°o h√†m H√†m K√≠ch ho·∫°t** l√™n Gradient (trong Backprop.). |\n",
    "| **ƒêi·ªÅu ki·ªán K√≠ch th∆∞·ªõc** | S·ªë c·ªôt Ma tr·∫≠n 1 = S·ªë h√†ng Ma tr·∫≠n 2. | Ph·∫£i c√≥ c√πng k√≠ch th∆∞·ªõc (H√†ng = H√†ng, C·ªôt = C·ªôt). |\n",
    "| **C√¥ng th·ª©c (V√≠ d·ª• $C=A \\cdot B$)** | $C_{ij} = \\sum_{k} A_{ik} B_{kj}$ | $C_{ij} = A_{ij} \\cdot B_{ij}$ |\n",
    "| **√ù nghƒ©a** | Bi·ªÉu di·ªÖn **Bi·∫øn ƒë·ªïi Tuy·∫øn t√≠nh** (Linear Transformation) | Bi·ªÉu di·ªÖn **Ph√©p to√°n tr√™n t·ª´ng ph·∫ßn t·ª≠** ƒë·ªôc l·∫≠p. |\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ·ª®ng d·ª•ng Chi ti·∫øt trong Neural Networks\n",
    "\n",
    "### 2.1. T√≠ch Ma tr·∫≠n Ti√™u chu·∫©n ($*$) - (Dot Product)\n",
    "\n",
    "Ph√©p nh√¢n ma tr·∫≠n l√† n·ªÅn t·∫£ng cho **qu√° tr√¨nh bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh** c·ªßa d·ªØ li·ªáu.\n",
    "\n",
    "#### A. Lan truy·ªÅn Xu√¥i (Forward Propagation)\n",
    "$$Z^{(i)} = W^{(i)} A^{(i-1)} + b^{(i)}$$\n",
    "\n",
    "* **M·ª•c ƒë√≠ch:** T√≠nh ƒë·∫ßu v√†o ch∆∞a k√≠ch ho·∫°t ($Z$) c·ªßa t·∫ßng $i$. ƒê√¢y l√† s·ª± k·∫øt h·ª£p tuy·∫øn t√≠nh c·ªßa Output t·∫ßng tr∆∞·ªõc ($A^{(i-1)}$) v·ªõi Tr·ªçng s·ªë ($W^{(i)}$).\n",
    "\n",
    "#### B. Lan truy·ªÅn Ng∆∞·ª£c (Backpropagation)\n",
    "$$\\frac{\\partial J}{\\partial A^{(i-1)}} = \\frac{\\partial J}{\\partial Z^{(i)}} * (W^{(i)})^T$$\n",
    "\n",
    "* **M·ª•c ƒë√≠ch:** Lan truy·ªÅn Gradient ($\\frac{\\partial J}{\\partial Z^{(i)}}$) qua ma tr·∫≠n Tr·ªçng s·ªë chuy·ªÉn v·ªã $(W^{(i)})^T$ ƒë·ªÉ t√¨m Gradient cho Output c·ªßa t·∫ßng tr∆∞·ªõc ($A^{(i-1)}$).\n",
    "\n",
    "**V√≠ d·ª•:**\n",
    "$$W = \\begin{pmatrix} 0.5 & 0.1 \\\\ 0.2 & 0.6 \\end{pmatrix}, \\quad A_{\\text{Input}} = \\begin{pmatrix} 4 \\\\ 2 \\end{pmatrix}$$\n",
    "$$Z = W \\cdot A_{\\text{Input}} = \\begin{pmatrix} 0.5 \\cdot 4 + 0.1 \\cdot 2 \\\\ 0.2 \\cdot 4 + 0.6 \\cdot 2 \\end{pmatrix} = \\begin{pmatrix} 2.2 \\\\ 2.0 \\end{pmatrix}$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2. T√≠ch Hadamard ($\\odot$ ho·∫∑c $\\otimes$) - (Element-wise)\n",
    "\n",
    "Ph√©p nh√¢n Hadamard l√† c·ªët l√µi trong vi·ªác t√≠nh to√°n ·∫£nh h∆∞·ªüng c·ªßa **H√†m K√≠ch ho·∫°t** l√™n Gradient.\n",
    "\n",
    "#### ·ª®ng d·ª•ng trong Backpropagation\n",
    "\n",
    "Ph√©p nh√¢n Hadamard ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√≠nh Gradient c·ªßa h√†m m·∫•t m√°t ($J$) ƒë·ªëi v·ªõi ƒë·∫ßu v√†o ch∆∞a k√≠ch ho·∫°t ($Z^{(i)}$):\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial Z^{(i)}} = \\frac{\\partial J}{\\partial A^{(i)}} \\odot \\frac{\\partial A^{(i)}}{\\partial Z^{(i)}}$$\n",
    "\n",
    "* **M·ª•c ƒë√≠ch:** K·∫øt h·ª£p Gradient t·ª´ t·∫ßng sau ($\\frac{\\partial J}{\\partial A^{(i)}}$) v·ªõi ƒê·∫°o h√†m c·ªßa H√†m K√≠ch ho·∫°t ($\\frac{\\partial A^{(i)}}{\\partial Z^{(i)}}$). V√¨ h√†m k√≠ch ho·∫°t (nh∆∞ Sigmoid, ReLU) t√°c ƒë·ªông ƒë·ªôc l·∫≠p l√™n t·ª´ng n∆°-ron, ph√©p nh√¢n n√†y ph·∫£i l√† **element-wise**.\n",
    "* **C√¥ng th·ª©c ƒê·∫°o h√†m Sigmoid (V√≠ d·ª•):** $\\frac{\\partial A^{(i)}}{\\partial Z^{(i)}} = A^{(i)} \\odot (1 - A^{(i)})$\n",
    "\n",
    "**V√≠ d·ª•:**\n",
    "* Gi·∫£ s·ª≠ Gradient t·ª´ t·∫ßng sau: $dA = \\begin{pmatrix} -0.1 \\\\ 0.3 \\end{pmatrix}$\n",
    "* Gi·∫£ s·ª≠ ƒê·∫°o h√†m c·ªßa Activation: $g'(Z) = \\begin{pmatrix} 0.2 \\\\ 0.25 \\end{pmatrix}$\n",
    "$$\\frac{\\partial J}{\\partial Z} = dA \\odot g'(Z) = \\begin{pmatrix} -0.1 \\\\ 0.3 \\end{pmatrix} \\odot \\begin{pmatrix} 0.2 \\\\ 0.25 \\end{pmatrix} = \\begin{pmatrix} -0.02 \\\\ 0.075 \\end{pmatrix}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. ‚ö†Ô∏è L∆∞u √Ω Quan tr·ªçng\n",
    "\n",
    "* Hai ph√©p to√°n n√†y **KH√îNG TH·ªÇ THAY TH·∫æ CHO NHAU**. Vi·ªác √°p d·ª•ng sai ph√©p to√°n s·∫Ω l√†m h·ªèng k√≠ch th∆∞·ªõc ma tr·∫≠n v√† vi ph·∫°m quy t·∫Øc chu·ªói c·ªßa ƒë·∫°o h√†m.\n",
    "* Trong nhi·ªÅu t√†i li·ªáu DL, k√Ω hi·ªáu $\\otimes$ ƒë∆∞·ª£c s·ª≠ d·ª•ng thay cho $\\odot$ ƒë·ªÉ ch·ªâ T√≠ch Hadamard. Lu√¥n lu√¥n ki·ªÉm tra ch√∫ th√≠ch c·ªßa t√†i li·ªáu (nh∆∞ trong c√¥ng th·ª©c Backpropagation c·ªßa b·∫°n) ƒë·ªÉ x√°c ƒë·ªãnh r√µ √Ω nghƒ©a c·ªßa k√Ω hi·ªáu."
   ],
   "id": "592bf2e7c18ac5f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
